{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOyFFdwqZnr74w3nA0w0gZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaen/machine-learning-notes/blob/main/llm/transformers/decoder/decoder_block.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decoder Implementation From Scratch**"
      ],
      "metadata": {
        "id": "6r_RfZdu-GPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```text\n",
        "workflow\n",
        "========\n",
        "1. Input text\n",
        "2. Right shift (cut the last token of each sentence)\n",
        "3. Embeddings\n",
        "4. Positional Encoding\n",
        "5. Masked-Multi-Head Attention (each token only can see previous and self token)\n",
        "6. Add/Norm\n",
        "7. FFN\n",
        "8. Add/Norm\n",
        "```"
      ],
      "metadata": {
        "id": "i7Bb0Na1_7DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "oLDeucK4Cfcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dummy Data**"
      ],
      "metadata": {
        "id": "zCfhQeWSAqeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Positional Encoding**"
      ],
      "metadata": {
        "id": "QrcsH0P9L3cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(x: torch.Tensor) -> torch.Tensor:\n",
        "    # with sinoudial equation\n",
        "    # sinosoidal equation\n",
        "    # pos = idx of the token\n",
        "    # i   = idx of each token feature\n",
        "    #\n",
        "    # if embedded feature idx is even:\n",
        "    #  sin(pos / 10000 ^ (2i / d_model))\n",
        "    #\n",
        "    # if embedded feature idx is odd:\n",
        "    #  cos(pos / 1000 ^ (2i / d_model))\n",
        "\n",
        "    seq_len, d_model = x.shape\n",
        "    c_val = torch.tensor(10000)\n",
        "\n",
        "    result = []\n",
        "    for pos, t_feature in enumerate(x):\n",
        "        each = []\n",
        "        for i, _ in enumerate(t_feature):\n",
        "            # check the token feature idx if even or odd\n",
        "            if i % 2 == 0:\n",
        "                each.append(torch.sin(\n",
        "                    (pos / torch.pow(c_val, torch.tensor((2*i / d_model))))\n",
        "                    ))\n",
        "            else:\n",
        "                each.append(torch.cos(\n",
        "                    (pos / torch.pow(c_val, torch.tensor((2*i / d_model))))\n",
        "                    ))\n",
        "        result.append(each)\n",
        "\n",
        "    return torch.tensor(result)"
      ],
      "metadata": {
        "id": "P5NO4aBTCxoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Masked Multi-Head Attention Block**"
      ],
      "metadata": {
        "id": "81K9qekivF69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedMultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, no_of_heads: int) -> None:\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            no_of_heads (int) : number of heads\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.d_model = d_model\n",
        "        self.no_of_heads = no_of_heads\n",
        "        self.dk = self.d_model // self.no_of_heads\n",
        "        print(f\"Initialize MaskedMultiHeadAttention with \\n{self.d_model=}\\n{self.no_of_heads=}\")\n",
        "\n",
        "        self.q_w = torch.nn.Linear(self.d_model, self.d_model)\n",
        "        self.k_w = torch.nn.Linear(self.d_model, self.d_model)\n",
        "        self.v_w = torch.nn.Linear(self.d_model, self.d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x (Tensor)  : input data\n",
        "\n",
        "        Returns:\n",
        "            Tensor : output logits\n",
        "        \"\"\"\n",
        "        self.seq_len, self.d_model = x.shape\n",
        "        # calcualte Q, K, V\n",
        "        Q = self.q_w(x)\n",
        "        K = self.k_w(x)\n",
        "        V = self.v_w(x)\n",
        "\n",
        "        # split Q, K, V for multi-head attenions.\n",
        "        # Each head get no.of feature / specific part of each token\n",
        "        # So, each heads can focus singe token in many view\n",
        "        m_q = Q.view(self.seq_len, self.no_of_heads, self.dk).transpose(0, 1)\n",
        "        m_k = K.view(self.seq_len, self.no_of_heads, self.dk).transpose(0, 1)\n",
        "        m_v = V.view(self.seq_len, self.no_of_heads, self.dk).transpose(0, 1)\n",
        "\n",
        "        # calculate attention scores\n",
        "        # attention(q, k, v) = softmax(Q*K^T / sqrt(dk)) * V\n",
        "        mask = torch.tril(torch.ones(self.seq_len, self.seq_len)).bool()\n",
        "        scores = []\n",
        "        for q, k, v in zip(m_q, m_k, m_v):\n",
        "            score = ( q @ k.T ) / torch.sqrt(torch.tensor(self.dk))\n",
        "\n",
        "            # masking\n",
        "            # here what is diff in masked attention\n",
        "            # we\n",
        "            masked_score = score.masked_fill(~mask, -1e9)\n",
        "\n",
        "            scores.append(torch.softmax(masked_score, dim=1) @ v)\n",
        "        tensor_result = torch.stack(scores, dim=0)\n",
        "        return tensor_result.transpose(1, 0).reshape(self.seq_len, self.d_model)\n"
      ],
      "metadata": {
        "id": "ipByiuT3JV_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Add/Norm**"
      ],
      "metadata": {
        "id": "YGvN6TolvN-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# add = just add input + sublayer output\n",
        "# norm = apply layernorm\n",
        "\n",
        "def residual_norm(\n",
        "        x: torch.Tensor,\n",
        "        output: torch.Tensor,\n",
        "        layer_norm: torch.nn.modules.normalization.LayerNorm) -> torch.Tensor:\n",
        "        return layer_norm(x + output)"
      ],
      "metadata": {
        "id": "4rk5-lZvvNrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Full Decoder**"
      ],
      "metadata": {
        "id": "xYzagsiG0dK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "    def __init__(self, no_of_heads: int, d_model: int) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.mmha = MaskedMultiHeadAttention(no_of_heads=no_of_heads)\n",
        "        self.ffn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(d_model, 4*d_model),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(4*d_model, d_model),\n",
        "        )\n",
        "        self.norm1 = torch.nn.LayerNorm(d_model)\n",
        "        self.norm2 = torch.nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        X = positional_encoding(x)\n",
        "        attention_score = self.mmha(X)\n",
        "        r1 = residual_norm(X, attention_score, self.norm1)\n",
        "        ffn_result = self.ffn(r1)\n",
        "        r2 = residual_norm(r1, ffn_result, self.norm2)\n",
        "        return r2"
      ],
      "metadata": {
        "id": "kIW9iC5GyddD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1hzy5n097WZ",
        "outputId": "c5bb4f0f-f871-499f-98e5-c8936cef36c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "# 10 tokens\n",
        "# each token embedding into (20,)\n",
        "input_embd = torch.randn(10, 20)\n",
        "input_embd.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(5, d_model=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFx3D0qByi9b",
        "outputId": "d4ff8b57-29a0-497f-c595-69e1c2582640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialize MaskedMultiHeadAttention with \n",
            "self.d_model=20\n",
            "self.no_of_heads=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = decoder(input_embd)\n",
        "res.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi--UIPNyjoM",
        "outputId": "c8bb08dc-8c39-4964-a447-8e6e4e857209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHcAusYe0y7g",
        "outputId": "6ecec837-0bb5-4e6c-8b1b-40e93e46753b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9239,  1.2566, -0.6877,  0.7834, -0.3338,  2.0210, -0.8523,  1.0145,\n",
              "         -0.3438,  1.1300, -0.2573,  1.0362, -0.9080,  0.5436, -1.8957,  1.0866,\n",
              "         -0.8638, -0.1872, -0.8759, -0.7425],\n",
              "        [ 0.4649,  1.1696, -0.4438,  0.6514, -0.1518,  1.9474, -0.7795,  0.9397,\n",
              "         -0.3069,  1.0864, -0.5282,  1.0733, -1.0994,  0.2523, -1.9820,  1.0067,\n",
              "         -1.1976, -0.0409, -1.0935, -0.9680],\n",
              "        [ 0.6025,  0.8062, -0.1172,  0.5892, -0.0522,  1.8884, -0.7160,  0.9119,\n",
              "         -0.2837,  1.1774, -0.6398,  1.1506, -1.1129,  0.2182, -1.9575,  1.0264,\n",
              "         -1.3581,  0.0911, -1.1973, -1.0272],\n",
              "        [-0.7122,  0.2606,  0.2929,  0.6184, -0.0198,  1.8739, -0.6619,  0.9727,\n",
              "         -0.2520,  1.4469, -0.6377,  1.2830, -0.9987,  0.4409, -1.8381,  1.1659,\n",
              "         -1.2968,  0.1444, -1.1995, -0.8827],\n",
              "        [-1.9965, -0.3706,  0.5806,  0.6356, -0.0470,  1.5997, -0.5923,  0.8805,\n",
              "         -0.1600,  1.5686, -0.5690,  1.2910, -0.7630,  0.6952, -1.5380,  1.1524,\n",
              "         -0.9452,  0.1310, -0.9961, -0.5569],\n",
              "        [-2.1704, -0.9315,  0.7483,  0.6252, -0.0211,  1.4262, -0.5940,  0.7673,\n",
              "         -0.1107,  1.6140, -0.5444,  1.3035, -0.6802,  0.7685, -1.3787,  1.1268,\n",
              "         -0.8296,  0.1459, -0.9048, -0.3603],\n",
              "        [-1.2743, -1.5298,  0.9402,  0.5969,  0.0942,  1.4116, -0.6956,  0.6730,\n",
              "         -0.1291,  1.6748, -0.6504,  1.3983, -0.8105,  0.6838, -1.4274,  1.1550,\n",
              "         -1.0138,  0.2249, -0.9848, -0.3371],\n",
              "        [ 0.2006, -1.9212,  1.0826,  0.4931,  0.1967,  1.3150, -0.7527,  0.5425,\n",
              "         -0.2011,  1.5455, -0.7097,  1.4079, -0.9318,  0.4802, -1.4964,  1.0864,\n",
              "         -1.2341,  0.2933, -1.0200, -0.3767],\n",
              "        [ 0.7532, -1.9488,  1.1456,  0.3815,  0.2090,  1.1872, -0.7125,  0.4562,\n",
              "         -0.2266,  1.4637, -0.7513,  1.4067, -0.9393,  0.3995, -1.4477,  1.0240,\n",
              "         -1.2988,  0.3651, -1.0405, -0.4263],\n",
              "        [-0.1277, -1.7704,  1.3124,  0.3093,  0.2111,  1.1521, -0.7148,  0.5216,\n",
              "         -0.1999,  1.6534, -0.8264,  1.4843, -0.9092,  0.4991, -1.3536,  1.1200,\n",
              "         -1.2773,  0.3638, -1.0724, -0.3751]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIQ4DCaU0-h2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}