{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpBTPW8I6wjYLCwouTKr8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaen/machine-learning-notes/blob/main/llm/attention/attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZn9a6EOytCf"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing & Embedding"
      ],
      "metadata": {
        "id": "8rDA-xQUO-Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"the cat sat on mat\"\n",
        "text_idx = torch.tensor([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "id": "vT8cBewPOS11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE: int = 6\n",
        "EMBEDDING_DIM: int = 2\n",
        "\n",
        "embedder = torch.nn.Embedding(num_embeddings=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM)\n",
        "embd_text = embedder(text_idx)\n",
        "print(f\"Each word get (1,2) sized embedding vector\")\n",
        "print(f\"embedding for  'the' : {embd_text[0]}\")\n",
        "print(f\"embedding for  'cat' : {embd_text[1]}\")\n",
        "print(f\"embedding for  'sat' : {embd_text[2]}\")\n",
        "print(f\"embedding for  'on' : {embd_text[3]}\")\n",
        "print(f\"embedding for  'mat' : {embd_text[4]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjF8gtj_OVjo",
        "outputId": "027895ca-c21e-48ff-9938-ef9ce164200f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each word get (1,2) sized embedding vector\n",
            "embedding for  'the' : tensor([0.5517, 1.2525], grad_fn=<SelectBackward0>)\n",
            "embedding for  'cat' : tensor([1.1554, 1.3356], grad_fn=<SelectBackward0>)\n",
            "embedding for  'sat' : tensor([-0.0685,  0.6911], grad_fn=<SelectBackward0>)\n",
            "embedding for  'on' : tensor([-0.5127,  0.6953], grad_fn=<SelectBackward0>)\n",
            "embedding for  'mat' : tensor([0.3279, 1.6875], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Query, Key, Value"
      ],
      "metadata": {
        "id": "w5oF0q3MPDDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ATTENTION_DIM: int = 3\n",
        "\n",
        "Q_W = torch.nn.Linear(EMBEDDING_DIM, ATTENTION_DIM)\n",
        "K_W = torch.nn.Linear(EMBEDDING_DIM, ATTENTION_DIM)\n",
        "V_W = torch.nn.Linear(EMBEDDING_DIM, ATTENTION_DIM)"
      ],
      "metadata": {
        "id": "0krzkljEO1xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = Q_W(embd_text)\n",
        "K = K_W(embd_text)\n",
        "V = V_W(embd_text)"
      ],
      "metadata": {
        "id": "oj-jTVz5aj-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPaPlFhvbPC7",
        "outputId": "f9ef3bb1-657c-4d32-d258-2fb3170ec237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8839,  0.1819, -1.2290],\n",
              "        [-1.0480,  0.0450, -1.4616],\n",
              "        [-0.6030,  0.0626, -0.8578],\n",
              "        [-0.4977,  0.1991, -0.7049],\n",
              "        [-0.9331,  0.4870, -1.2723]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "K"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuNf99HNbSCo",
        "outputId": "bd142895-5112-4b15-f748-e4668de0c60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3891, -0.8027,  0.7165],\n",
              "        [ 0.7597, -0.8657,  1.1348],\n",
              "        [ 0.2505, -0.4388,  0.0124],\n",
              "        [-0.0555, -0.4335, -0.2577],\n",
              "        [ 0.0146, -1.0722,  0.8299]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEut2BbRbSYv",
        "outputId": "5e0dfa95-5a83-43d8-d9f5-af02028c7ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5666,  0.6943, -0.0059],\n",
              "        [-0.7490,  0.5401, -0.2813],\n",
              "        [-0.3925,  0.6570,  0.2172],\n",
              "        [-0.2565,  0.7974,  0.4280],\n",
              "        [-0.4862,  0.9432,  0.1547]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Attention Score"
      ],
      "metadata": {
        "id": "GyLNw1-bbU56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention(Q, K, V) = softmax((Q*K^T) / root of dk) * V"
      ],
      "metadata": {
        "id": "9-Nan7EFbTlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = ATTENTION_DIM\n",
        "first_term = Q @ K.T / torch.sqrt(torch.tensor(d_k))\n",
        "first_term"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FeapZgkcIFZ",
        "outputId": "1eab111d-d1dd-4466-cf9e-32c25cad925b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7913, -1.2839, -0.1827,  0.1657, -0.7090],\n",
              "        [-0.8609, -1.4398, -0.1734,  0.2398, -0.7370],\n",
              "        [-0.5193, -0.8578, -0.1092,  0.1313, -0.4549],\n",
              "        [-0.4956, -0.7796, -0.1275,  0.0710, -0.4652],\n",
              "        [-0.9616, -1.4863, -0.2674,  0.0974, -0.9190]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob_w = torch.softmax(first_term, dim=1)\n",
        "print(f\"Relation between each word and it-self\")\n",
        "print(f\"'the' (pos: 0) relate more to   : {prob_w[0]}\")\n",
        "print(f\"'cat' (pos: 1) relate more to   : {prob_w[1]}\")\n",
        "print(f\"'sat' (pos: 2) relate more to   : {prob_w[2]}\")\n",
        "print(f\"'on'  (pos: 3) relate more to   : {prob_w[3]}\")\n",
        "print(f\"'mat' (pos: 4) relate more to   : {prob_w[4]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnlnwa-4cmHi",
        "outputId": "15859646-7d6f-481b-81f0-d5d9b24b0c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relation between each word and it-self\n",
            "'the' (pos: 0) relate more to   : tensor([0.1401, 0.0856, 0.2574, 0.3648, 0.1521], grad_fn=<SelectBackward0>)\n",
            "'cat' (pos: 1) relate more to   : tensor([0.1301, 0.0729, 0.2587, 0.3911, 0.1472], grad_fn=<SelectBackward0>)\n",
            "'sat' (pos: 2) relate more to   : tensor([0.1612, 0.1149, 0.2429, 0.3090, 0.1719], grad_fn=<SelectBackward0>)\n",
            "'on'  (pos: 3) relate more to   : tensor([0.1669, 0.1256, 0.2412, 0.2942, 0.1721], grad_fn=<SelectBackward0>)\n",
            "'mat' (pos: 4) relate more to   : tensor([0.1330, 0.0787, 0.2662, 0.3834, 0.1388], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = prob_w @ V\n",
        "# final result always the same shape of V\n",
        "print(\"Since attention_dim is 3, each word get (1,3) weight\")\n",
        "print(f\"This is the final Weighted sum, which is act as embedd in upcoming layer.\")\n",
        "print(f\"'the' : {result[0]}\")\n",
        "print(f\"'cat' : {result[1]}\")\n",
        "print(f\"'sat' : {result[2]}\")\n",
        "print(f\"'on'  : {result[3]}\")\n",
        "print(f\"'mat' : {result[4]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LySVwhfge7ZD",
        "outputId": "2861e2ae-07b1-410e-f224-12b1b0e48af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Since attention_dim is 3, each word get (1,3) weight\n",
            "This is the final Weighted sum, which is act as embedd in upcoming layer.\n",
            "'the' : tensor([-0.4120,  0.7470,  0.2107], grad_fn=<SelectBackward0>)\n",
            "'cat' : tensor([-0.4017,  0.7504,  0.2251], grad_fn=<SelectBackward0>)\n",
            "'sat' : tensor([-0.4356,  0.7422,  0.1784], grad_fn=<SelectBackward0>)\n",
            "'on'  : tensor([-0.4424,  0.7391,  0.1686], grad_fn=<SelectBackward0>)\n",
            "'mat' : tensor([-0.4045,  0.7463,  0.2205], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3-rL7ruLtdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}