{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMom3lmaW3lUfUXzTiKgmIj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnaen/machine-learning-notes/blob/main/llm/transformers/multi_head_attention/multi_head_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MULTI-HEAD ATTENTION WORKFLOW**\n",
        "\n",
        "1. Input text preprocessing\n",
        "    - Tokenize\n",
        "    - Vocab indexing\n",
        "    - Embedding each token\n",
        "\n",
        "2. Calculate Q, K, V with the input embedding\n",
        "3. Split Q, K, V outputs with no.of heads\n",
        "4. Calculate Attention score for each heads\n",
        "5. Combine them together, pass a final Linear Layer."
      ],
      "metadata": {
        "id": "E2ZDre3tT6QS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "ew3YSpm-GBTr"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Preprocessing"
      ],
      "metadata": {
        "id": "HY4YVC4LVD4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text: str = \"i love to code\"\n",
        "vocab_idx = torch.tensor([0, 1, 2, 3])  # vocab index"
      ],
      "metadata": {
        "id": "RFqV2ThMGnIr"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_OF_HEADS: int = 2\n",
        "EMBEDDING_DIM: int = 4  # a.k.a d_model\n",
        "D_K: float = EMBEDDING_DIM // NUM_OF_HEADS"
      ],
      "metadata": {
        "id": "KQ6OFuWjqH_5"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding input tokens\n",
        "\n",
        "embedder = torch.nn.Embedding(num_embeddings=4, embedding_dim=EMBEDDING_DIM)\n",
        "embedded_text = embedder(vocab_idx)\n",
        "embedded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--1fVBKJGycx",
        "outputId": "841803d8-9ebf-4360-ee9b-640642086f4f"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5008, -1.6228,  0.5575,  0.8338],\n",
              "        [-2.0577, -0.4445,  1.1370,  2.4174],\n",
              "        [ 1.7751, -0.0243, -0.3921,  1.1995],\n",
              "        [-0.0620, -2.4201, -0.4190,  1.7088]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Q, K, V"
      ],
      "metadata": {
        "id": "ecNEcjzAVbf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = torch.nn.Linear(EMBEDDING_DIM, EMBEDDING_DIM)\n",
        "K = torch.nn.Linear(EMBEDDING_DIM, EMBEDDING_DIM)\n",
        "V = torch.nn.Linear(EMBEDDING_DIM, EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "dkgakozspuzF"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_w = Q(embedded_text)\n",
        "k_w = K(embedded_text)\n",
        "v_w = V(embedded_text)"
      ],
      "metadata": {
        "id": "drXO_58cuYA-"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQpNfIpNusHi",
        "outputId": "811fb674-9ffa-46a6-c4c3-73f6f29c3c31"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0357, -0.0050, -0.9573,  0.1623],\n",
              "        [ 0.3952,  0.6331, -0.8375,  0.3189],\n",
              "        [ 0.1392, -0.0054, -0.6463,  0.1741],\n",
              "        [-0.7766,  0.4740,  0.2468,  0.4739]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k_w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7emnQZWvHmg",
        "outputId": "e2c20b66-0b06-4f3e-a350-9a78c9e9e814"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8485, -0.0183, -0.7542, -0.5700],\n",
              "        [ 0.7656,  0.3594, -1.2888, -1.2898],\n",
              "        [ 0.9554,  0.5377, -0.3983, -0.2228],\n",
              "        [-0.9299, -0.6553,  0.5126,  1.5518]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmEO04vYvNOJ",
        "outputId": "386e56f7-8053-4f39-f0d7-c113120466b9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4343, -0.4957,  0.2706,  1.2963],\n",
              "        [ 0.0052, -0.6249, -0.3505,  1.8123],\n",
              "        [ 0.5499, -0.3414,  0.2242,  0.7206],\n",
              "        [-0.9433,  0.7010,  0.4386, -0.3949]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Q, K, V for multiple heads"
      ],
      "metadata": {
        "id": "WrKQM37MzIob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split_q = q_w.view(4, NUM_OF_HEADS, D_K).transpose(0,1)  # 4 is seq_len\n",
        "split_q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcIoNzUjvN9O",
        "outputId": "2ffc58c7-1505-41f6-fd76-a2580927f36a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0357, -0.0050],\n",
              "         [ 0.3952,  0.6331],\n",
              "         [ 0.1392, -0.0054],\n",
              "         [-0.7766,  0.4740]],\n",
              "\n",
              "        [[-0.9573,  0.1623],\n",
              "         [-0.8375,  0.3189],\n",
              "         [-0.6463,  0.1741],\n",
              "         [ 0.2468,  0.4739]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_k = k_w.view(4, NUM_OF_HEADS, D_K).transpose(0,1)\n",
        "split_k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVKDGLSa7DSu",
        "outputId": "0690b888-0a02-4c69-e3ed-ba8039b3b5af"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.8485, -0.0183],\n",
              "         [ 0.7656,  0.3594],\n",
              "         [ 0.9554,  0.5377],\n",
              "         [-0.9299, -0.6553]],\n",
              "\n",
              "        [[-0.7542, -0.5700],\n",
              "         [-1.2888, -1.2898],\n",
              "         [-0.3983, -0.2228],\n",
              "         [ 0.5126,  1.5518]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_v = v_w.view(4, NUM_OF_HEADS, D_K).transpose(0, 1)\n",
        "split_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYC9pLII7OQJ",
        "outputId": "f14cf951-e9bf-40fe-a965-df1662f6bdee"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4343, -0.4957],\n",
              "         [ 0.0052, -0.6249],\n",
              "         [ 0.5499, -0.3414],\n",
              "         [-0.9433,  0.7010]],\n",
              "\n",
              "        [[ 0.2706,  1.2963],\n",
              "         [-0.3505,  1.8123],\n",
              "         [ 0.2242,  0.7206],\n",
              "         [ 0.4386, -0.3949]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Attention score for each heads"
      ],
      "metadata": {
        "id": "FE5-2ymxVn6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention_score(\n",
        "        q: torch.Tensor,\n",
        "        k: torch.Tensor,\n",
        "        v: torch.Tensor,\n",
        "        dk: torch.Tensor) -> torch.Tensor:\n",
        "\n",
        "        # attention = softmax(q*k^T / root of dk) * v\n",
        "        r_1 = (q @ k.T) / torch.sqrt(dk)\n",
        "        return torch.softmax(r_1, dim=1) @ v"
      ],
      "metadata": {
        "id": "-3tOMUe1G9el"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "for q_i, k_i, v_i in zip(split_q, split_k, split_v):\n",
        "    res.append(attention_score(q_i, k_i, v_i, dk=torch.tensor(D_K)))\n",
        "res"
      ],
      "metadata": {
        "id": "FUCPyV6gyOfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cde6aacd-c4f7-411f-9877-2e03775ed025"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.0217, -0.1993],\n",
              "         [ 0.1869, -0.3428],\n",
              "         [ 0.0521, -0.2263],\n",
              "         [-0.1752, -0.0223]], grad_fn=<MmBackward0>),\n",
              " tensor([[0.0619, 1.1051],\n",
              "         [0.1031, 0.9833],\n",
              "         [0.1002, 0.9954],\n",
              "         [0.2571, 0.4498]], grad_fn=<MmBackward0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = torch.stack(res, dim=0)\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzLRRKHB8MRl",
        "outputId": "7d4b56f7-e7f1-4a48-e6df-387759f7a049"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0217, -0.1993],\n",
              "         [ 0.1869, -0.3428],\n",
              "         [ 0.0521, -0.2263],\n",
              "         [-0.1752, -0.0223]],\n",
              "\n",
              "        [[ 0.0619,  1.1051],\n",
              "         [ 0.1031,  0.9833],\n",
              "         [ 0.1002,  0.9954],\n",
              "         [ 0.2571,  0.4498]]], grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.shape"
      ],
      "metadata": {
        "id": "4iFJPE-wDDzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38af0444-529a-44a2-97a2-6ef7762311d8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge all heads outputs"
      ],
      "metadata": {
        "id": "ZQKJjpyNVu78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = res.permute(1, 0, 2).reshape(4,4)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uogGmtzrQ0SR",
        "outputId": "ab6e2747-4f63-4121-c8cd-d8829d0d1f9d"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0217, -0.1993,  0.0619,  1.1051],\n",
              "        [ 0.1869, -0.3428,  0.1031,  0.9833],\n",
              "        [ 0.0521, -0.2263,  0.1002,  0.9954],\n",
              "        [-0.1752, -0.0223,  0.2571,  0.4498]], grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Linear Layer pass"
      ],
      "metadata": {
        "id": "8SuWRQmVVxuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "o_w = torch.nn.Linear(EMBEDDING_DIM, EMBEDDING_DIM)\n",
        "o_w(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCv4J1TCTZUz",
        "outputId": "9f910da2-a521-4870-ec36-389b5c85c53f"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1213, -0.1479,  0.5272, -0.5390],\n",
              "        [ 0.0650, -0.0441,  0.6500, -0.6313],\n",
              "        [ 0.0741, -0.0966,  0.5649, -0.5407],\n",
              "        [-0.1407,  0.0220,  0.5020, -0.2861]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TT3G0pAQThL6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}