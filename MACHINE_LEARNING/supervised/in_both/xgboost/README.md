# **XGBoost (Extreme Gradient Boosting)**

### About
- Models are trained sequentially, and each model corrects the errors of its predecessor by minimizing a loss function.

### Advantages
- Performance
- Speed

### Disadvantages
- Complexity
- High Resource Usage

### When to use
- When working on structured data.
- Dataset is too large.
- Accuracy and performance matters.
- Overfitting needs to be controlled
